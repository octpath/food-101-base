{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q loguru\n",
    "!pip install -q mlcrate\n",
    "!pip install -q omegaconf\n",
    "!pip install -q segmentation_models\n",
    "!pip install -q iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from loguru import logger\n",
    "import mlcrate as mlc\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-vacuum",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument('--config', required=True)\n",
    "parser.add_argument('options', nargs='*')\n",
    "args = parser.parse_args('--config ./config/base.yaml expr_name=hoge'.split())\n",
    "\n",
    "config = OmegaConf.load(args.config)\n",
    "config.merge_with_dotlist(args.options)\n",
    "\n",
    "OmegaConf.update(config.scheduler.params, 'num_epochs', config.num_epochs, merge=True)\n",
    "OmegaConf.update(config, 'save_path', os.path.join(config.save_root, config.expr_name), merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.device.name == 'gpu':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = config.device.id\n",
    "elif config.device.name == 'cpu':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import classification_models.tfkeras as cs\n",
    "import efficientnet.tfkeras as eff\n",
    "import scripts.schedulers\n",
    "import scripts.augmentations\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(config.seed)\n",
    "\n",
    "\n",
    "if config.device.name == 'tpu':\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "OmegaConf.update(config, 'batch_size', config.batch_size * strategy.num_replicas_in_sync, merge=True)\n",
    "OmegaConf.update(config, 'scheduler.params.init_lr', config.scheduler.params.init_lr * strategy.num_replicas_in_sync, merge=True)\n",
    "OmegaConf.update(config, 'scheduler.params.min_lr', config.scheduler.params.min_lr * strategy.num_replicas_in_sync, merge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-resource",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train/Val(/Test) List - CUSTOM\n",
    "'''\n",
    "\n",
    "def get_train_val_list(fold_idx):\n",
    "    dev_df = pd.read_csv('train.csv')\n",
    "    dev_df.fpath = config.data_root + 'images/' + dev_df.fpath\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=config.num_folds, shuffle=True, random_state=config.seed)\n",
    "    tidx, vidx = list(skf.split(dev_df, y=dev_df.label))[fold_idx]\n",
    "    \n",
    "    train_df = dev_df.iloc[tidx].reset_index(drop=True)\n",
    "    val_df = dev_df.iloc[vidx].reset_index(drop=True)\n",
    "    \n",
    "    return (train_df.fpath, train_df.label), (val_df.fpath, val_df.label)\n",
    "\n",
    "\n",
    "def get_test_list():\n",
    "    df = pd.read_csv('test.csv')\n",
    "    df.fpath = config.data_root + 'images/' + df.fpath\n",
    "    return df.fpath, df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transform\n",
    "'''\n",
    "def load_image(num_classes, fine_size, aug_func):\n",
    "    @tf.function\n",
    "    def load_image_(fpath, label):\n",
    "        img = tf.image.decode_jpeg(tf.io.read_file(fpath), channels=3)\n",
    "        img = tf.cast(tf.image.resize(img, fine_size), tf.uint8)\n",
    "        img = tf.ensure_shape(img, fine_size + (3,))\n",
    "        \n",
    "        if aug_func is not None:\n",
    "            img = aug_func(img)\n",
    "            \n",
    "        img = tf.cast(img, tf.float32) / 255.\n",
    "        label = tf.one_hot(label, num_classes)\n",
    "        return img, label\n",
    "    return load_image_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DataLoader\n",
    "'''\n",
    "def get_train_ds(train_data, num_classes, batch_size, train_size, aug_func):\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        train_data\n",
    "    ).shuffle(\n",
    "        len(train_data[0])\n",
    "    ).map(\n",
    "        load_image(num_classes, train_size, aug_func), num_parallel_calls=tf.data.AUTOTUNE, deterministic=False\n",
    "    ).batch(\n",
    "        batch_size, drop_remainder=True\n",
    "    ).repeat(-1).prefetch(1)\n",
    "\n",
    "    return train_ds\n",
    "\n",
    "\n",
    "def get_val_ds(val_data, num_classes, batch_size, val_size):\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        val_data\n",
    "    ).map(\n",
    "        load_image(num_classes, val_size, None), num_parallel_calls=tf.data.AUTOTUNE, deterministic=True\n",
    "    ).batch(\n",
    "        batch_size, drop_remainder=False\n",
    "    ).prefetch(1)\n",
    "    \n",
    "    return val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model - CUSTOM\n",
    "'''\n",
    "def build_model(input_shape, num_classes, dropout_rate, weight_decay, base_func, base_weights):\n",
    "    import os, tempfile\n",
    "    def add_regularization(model, weight_reg):\n",
    "        custom_objects={}\n",
    "        for layer in model.layers:\n",
    "            for attr in ['kernel_regularizer']:\n",
    "                if hasattr(layer, attr):\n",
    "                    setattr(layer, attr, tf.keras.regularizers.l2(weight_reg))\n",
    "        model_json = model.to_json()\n",
    "        tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n",
    "        model.save_weights(tmp_weights_path)\n",
    "        model = tf.keras.models.model_from_json(model_json, custom_objects=custom_objects)\n",
    "        model.load_weights(tmp_weights_path, by_name=True)\n",
    "        return model\n",
    "    \n",
    "    '''\n",
    "    model definition\n",
    "    '''\n",
    "    base_model = base_func(input_shape=input_shape, include_top=False, weights=base_weights)\n",
    "    \n",
    "    ip = tf.keras.layers.Input(input_shape)\n",
    "    h = base_model(ip)\n",
    "    h = tf.keras.layers.GlobalAveragePooling2D()(h)\n",
    "    h = tf.keras.layers.Dropout(dropout_rate)(h)\n",
    "    h = tf.keras.layers.Dense(num_classes, activation=tf.nn.sigmoid)(h)\n",
    "    model = tf.keras.models.Model(ip, h)\n",
    "    \n",
    "    if weight_decay > 0.:\n",
    "        model = add_regularization(model, weight_decay)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_regularizer_loss(model):\n",
    "    loss = 0\n",
    "    for l in model.layers:\n",
    "        if hasattr(l,'layers') and l.layers:\n",
    "            loss += model_regularizer_loss(l)\n",
    "        if hasattr(l,'kernel_regularizer') and l.kernel_regularizer:\n",
    "            loss += l.kernel_regularizer(l.kernel)\n",
    "        if hasattr(l,'bias_regularizer') and l.bias_regularizer:\n",
    "            loss += l.bias_regularizer(l.bias)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metrics - CUSTOM\n",
    "'''\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.scores = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "        self.loss = tf.keras.metrics.Mean()\n",
    "        self.header = ['loss'] + [f'score_{i+1}' for i in range(len(self.scores))]\n",
    "        self.df = pd.DataFrame(columns=self.header)\n",
    "    \n",
    "    def update_state(self, y_trues, y_preds, loss):\n",
    "        self.scores[0].update_state(y_trues, y_preds)\n",
    "        self.loss.update_state(loss)\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return self.loss.result().numpy()\n",
    "    \n",
    "    def get_scores(self):\n",
    "        score = self.scores[0].result().numpy()\n",
    "        return [score]\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.scores[0].reset_states()\n",
    "        self.loss.reset_states()\n",
    "    \n",
    "    def on_epoch_end(self, e):\n",
    "        self.df.loc[e] = [self.get_loss()] + self.get_scores()\n",
    "    \n",
    "    def get_latest(self):\n",
    "        return self.df.index.tolist()[-1], self.df.iloc[-1, :].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train/Val(/Test) Proc on epoch - Classification\n",
    "'''\n",
    "def get_proc_on_batch():\n",
    "    @tf.function\n",
    "    def train_on_batch(inputs, model, criterion, optimizer):\n",
    "        x, y = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            p = model(x, training=True)\n",
    "            loss = criterion(y, p)\n",
    "            total_loss = tf.reduce_mean(loss) + model_regularizer_loss(model)\n",
    "        grads = tape.gradient(loss, sources=model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return y, p, loss\n",
    "\n",
    "    @tf.function\n",
    "    def val_on_batch(inputs, model, criterion):\n",
    "        x, y = inputs\n",
    "        p = model(x, training=False)\n",
    "        loss = criterion(y, p)\n",
    "        return y, p, loss\n",
    "    \n",
    "    return train_on_batch, val_on_batch\n",
    "\n",
    "\n",
    "def proc_on_epoch(training, proc_on_batch, dataset, metrics, criterion, model, epoch, total_epoch, iters_per_epoch=None, optimizer=None):\n",
    "    \n",
    "    metrics.reset_state()\n",
    "    if training:\n",
    "        assert iters_per_epoch is not None\n",
    "        assert optimizer is not None\n",
    "        phase = 'train'\n",
    "    else:\n",
    "        phase = 'valid'\n",
    "    \n",
    "    with tqdm.tqdm(dataset, total=iters_per_epoch, ncols=0, desc=f'{phase} {(1+epoch)}/{total_epoch}') as tq:\n",
    "        for iter_i, inputs in enumerate(tq):\n",
    "            if training:\n",
    "                if iter_i > iters_per_epoch:\n",
    "                    break\n",
    "                y, p, loss = proc_on_batch(inputs, model, criterion, optimizer)\n",
    "            else:\n",
    "                y, p, loss = proc_on_batch(inputs, model, criterion)\n",
    "            \n",
    "            metrics.update_state(y, p, loss)\n",
    "            tq.set_postfix(OrderedDict(\n",
    "                loss = metrics.get_loss(),\n",
    "                scores = metrics.get_scores()\n",
    "            ))\n",
    "    \n",
    "    metrics.on_epoch_end(epoch+1)\n",
    "    if training:\n",
    "        return metrics, model, optimizer\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def proc_eval(phase, proc_on_batch, dataset, metrics, criterion, model):\n",
    "    assert phase in ['val', 'test']\n",
    "    \n",
    "    metrics.reset_state()\n",
    "    \n",
    "    trues = []\n",
    "    preds = []\n",
    "    with tqdm.tqdm(dataset, ncols=0, desc=f'{phase}') as tq:\n",
    "        for iter_i, inputs in enumerate(tq):\n",
    "            y, p, loss = proc_on_batch(inputs, model, criterion)\n",
    "            trues.append(y.numpy())\n",
    "            preds.append(p.numpy())\n",
    "            metrics.update_state(y, p, loss)\n",
    "            \n",
    "    scores = metrics.get_scores()\n",
    "    trues = np.concatenate(trues)\n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return scores, trues, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-catering",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(fold_idx, config):\n",
    "    \n",
    "    scheduler = eval(config.scheduler.name)(**config.scheduler.params)\n",
    "    optimizer = eval(config.optimizer.name)(**config.optimizer.params)\n",
    "    criterion = eval(config.loss.name)(**config.loss.params)\n",
    "    \n",
    "    train_metrics = Metrics()\n",
    "    val_metrics = Metrics()\n",
    "    \n",
    "    train_data, val_data = get_train_val_list(fold_idx)\n",
    "    train_iters_per_epoch = len(train_data[0]) // config.batch_size\n",
    "    \n",
    "    if config.has_test:\n",
    "        test_metrics = Metrics()\n",
    "        test_data = get_test_list()\n",
    "        test_ds = get_val_ds(\n",
    "            test_data,\n",
    "            config.num_classes, config.batch_size, \n",
    "            tuple(config.transform.test_size)\n",
    "        )\n",
    "    \n",
    "    best_score = 0.\n",
    "    best_loss = 10000.\n",
    "    \n",
    "    for e in range(config.num_epochs):\n",
    "\n",
    "        '''\n",
    "        init: dataset, inference_method, train/val_model\n",
    "        '''\n",
    "        if (e == 0) or (('stages' in config) and (e in config.stages.epochs)):\n",
    "            if ('stages' in config) and (e in config.stages.epochs):\n",
    "                '''\n",
    "                stage start\n",
    "                '''\n",
    "                stage_idx = config.stages.epochs.index(e)\n",
    "                config.transform = OmegaConf.merge(config.transform, config.stages.transforms[stage_idx])\n",
    "                config.model = OmegaConf.merge(config.model, config.stages.models[stage_idx])\n",
    "                if e > 0:\n",
    "                    logger.info(f'New Stage {stage_idx}')\n",
    "            \n",
    "            \n",
    "            train_ds = get_train_ds(\n",
    "                train_data,\n",
    "                config.num_classes, config.batch_size, \n",
    "                tuple(config.transform.train_size),\n",
    "                eval(config.transform.aug_name)(**config.transform.aug_params),\n",
    "            )\n",
    "            val_ds = get_val_ds(\n",
    "                val_data,\n",
    "                config.num_classes, config.batch_size, \n",
    "                tuple(config.transform.val_size)\n",
    "            )\n",
    "            \n",
    "            train_on_batch, val_on_batch = get_proc_on_batch()\n",
    "\n",
    "            with strategy.scope():\n",
    "                train_model = build_model(\n",
    "                    tuple(config.transform.train_size) + (3,), config.num_classes, weight_decay=config.loss.weight_decay,\n",
    "                    dropout_rate=config.model.dropout_rate, \n",
    "                    base_func=eval(config.model.base_func),\n",
    "                    base_weights=config.model.base_weights\n",
    "                )\n",
    "                if ('stages' in config) and (stage_idx > 0):\n",
    "                    train_model.load_weights(os.path.join(config.save_path, f'latest-{fold_idx}.h5'))\n",
    "                \n",
    "                val_model = build_model(\n",
    "                    tuple(config.transform.val_size) + (3,), config.num_classes, weight_decay=config.loss.weight_decay,\n",
    "                    dropout_rate=config.model.dropout_rate,\n",
    "                    base_func=eval(config.model.base_func),\n",
    "                    base_weights=config.model.base_weights\n",
    "                )\n",
    "        \n",
    "        '''\n",
    "        logger start\n",
    "        '''\n",
    "        if e == 0:\n",
    "            csv_logger = mlc.LinewiseCSVWriter(\n",
    "                os.path.join(config.save_path, f'log-{fold_idx}.csv'),\n",
    "                header=['epoch'] + [f'train_{h}' for h in train_metrics.header] + [f'val_{h}' for h in val_metrics.header]\n",
    "            )\n",
    "            timer = mlc.time.Timer()\n",
    "            logger.info(f'fold-{fold_idx} start')\n",
    "\n",
    "\n",
    "        '''\n",
    "        train\n",
    "        '''\n",
    "        timer.add('train')\n",
    "        train_metrics, train_model, optimizer = proc_on_epoch(\n",
    "            True, train_on_batch, train_ds, train_metrics, criterion, train_model, e, config.num_epochs, \n",
    "            iters_per_epoch=train_iters_per_epoch, optimizer=optimizer\n",
    "        )\n",
    "        train_elapsed = timer.fsince('train')\n",
    "\n",
    "\n",
    "        '''\n",
    "        val\n",
    "        '''\n",
    "        val_model.set_weights(train_model.get_weights())\n",
    "        timer.add('val')\n",
    "        val_metrics = proc_on_epoch(\n",
    "            False, val_on_batch, val_ds, val_metrics, criterion, val_model, e, config.num_epochs, \n",
    "        )\n",
    "        val_elapsed = timer.fsince('val')\n",
    "\n",
    "\n",
    "        '''\n",
    "        log\n",
    "        '''\n",
    "        logger.info(f'epoch: {e+1} train: {train_elapsed} val: {val_elapsed}')\n",
    "        logger.info(f'train: {train_metrics.get_latest()[1]}')\n",
    "        logger.info(f'val: {val_metrics.get_latest()[1]}')\n",
    "        csv_logger.write([e+1] + train_metrics.get_latest()[1] + val_metrics.get_latest()[1])\n",
    "\n",
    "\n",
    "        '''\n",
    "        save\n",
    "        '''\n",
    "        val_model.save(os.path.join(config.save_path, f'latest-{fold_idx}.h5'))\n",
    "\n",
    "        val_loss = val_metrics.get_loss()\n",
    "        if val_loss < best_loss:\n",
    "            logger.info(f'loss got improved: {best_loss:.4f} to {val_loss:.4f}')\n",
    "            best_loss = val_loss\n",
    "            val_model.save(os.path.join(config.save_path, f'best_loss-{fold_idx}.h5'))\n",
    "\n",
    "        val_score = val_metrics.get_scores()[0]\n",
    "        if val_score > best_score:\n",
    "            logger.info(f'score got improved: {best_score:.4f} to {val_score:.4f}')\n",
    "            best_score = val_score\n",
    "            val_model.save(os.path.join(config.save_path, f'best_score-{fold_idx}.h5'))\n",
    "            \n",
    "            \n",
    "        '''\n",
    "        lr update\n",
    "        '''\n",
    "        curr_lr = optimizer.learning_rate.numpy()\n",
    "        next_lr = scheduler.get_next_lr(e+1, val_loss, val_score)\n",
    "        optimizer.learning_rate = next_lr\n",
    "        if curr_lr != next_lr:\n",
    "            logger.info(f'    lr {curr_lr} -> {next_lr}')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    oof\n",
    "    '''\n",
    "    val_model.load_weights(os.path.join(config.save_path, f'best_score-{fold_idx}.h5'))\n",
    "    val_scores, val_trues, val_preds = proc_eval('val', val_on_batch, val_ds, val_metrics, criterion, val_model)\n",
    "    np.savetxt(os.path.join(config.save_path, f'val_scores-{fold_idx}.txt'), np.array(val_scores))\n",
    "    if config.save_preds:\n",
    "        np.save(os.path.join(config.save_path, f'val_preds-{fold_idx}.npy'), val_preds)\n",
    "        \n",
    "    logger.info(f'fold-{fold_idx} val: {val_scores[0]:.4f}')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    test\n",
    "    '''\n",
    "    if config.has_test:\n",
    "        test_scores, test_trues, test_preds = proc_eval('test', val_on_batch, test_ds, test_metrics, criterion, val_model)\n",
    "        np.savetxt(os.path.join(config.save_path, f'test_scores-{fold_idx}.txt'), np.array(test_scores))\n",
    "        if config.save_preds:\n",
    "            np.save(os.path.join(config.save_path, f'test_preds-{fold_idx}.npy'), test_preds)\n",
    "            \n",
    "        logger.info(f'fold-{fold_idx} test: {test_scores[0]:.4f}')\n",
    "    \n",
    "    \n",
    "    logger.info(f'fold-{fold_idx} end')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    os.makedirs(config.save_path, exist_ok=True)\n",
    "    logger.add(os.path.join(config.save_path, 'log.txt'), mode='w')\n",
    "    OmegaConf.save(config, os.path.join(config.save_path, f'{config.expr_name}.yaml'))\n",
    "    \n",
    "    logger.info(f'{config.expr_name} start')\n",
    "    \n",
    "    for fold_idx in range(config.num_folds):\n",
    "        run_fold(fold_idx, config)\n",
    "        \n",
    "        if config.run_fold1_only:\n",
    "            break\n",
    "    \n",
    "    '''\n",
    "    mean test\n",
    "    '''\n",
    "    test_score = []\n",
    "    for fpath in sorted(glob.glob(os.path.join(config.save_path, f'test_scores-*.txt'))):\n",
    "        score = np.loadtxt(fpath)\n",
    "        if score.ndim > 0:\n",
    "            score = score[0]\n",
    "        test_score.append(score)\n",
    "    test_score = np.mean(test_score)\n",
    "    \n",
    "    with open(f'{config.expr_name}_{test_score:.6f}.rslt', 'w') as f:\n",
    "        pass\n",
    "    \n",
    "    logger.info(f'mean test score: {test_score}')\n",
    "    logger.info(f'{config.expr_name} end')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-mistress",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
